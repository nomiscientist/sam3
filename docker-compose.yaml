services:
  frontend:
    image: sam2/frontend
    build:
      context: ./demo/frontend
      dockerfile: frontend.Dockerfile
    ports:
      - 7262:80
    environment:
      - VITE_BACKEND_URL=http://localhost:7263
      - VITE_MAX_UPLOAD_SIZE=500
      - NODE_ENV=production
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  backend:
    image: sam2/backend
    build:
      context: .
      dockerfile: backend.Dockerfile
    ports:
      - 7263:5000
    volumes:
      - ./demo/data/:/data/:rw
      - ./demo/data/posters:/app/posters:rw
    environment:
      - SERVER_ENVIRONMENT=DEV
      - GUNICORN_WORKERS=1
      # Inference API needs to have at least 2 threads to handle an incoming
      # parallel cancel propagation request
      - GUNICORN_THREADS=2
      - GUNICORN_PORT=5000
      - API_URL=http://localhost:7263
      - DEFAULT_VIDEO_PATH=gallery/05_default_juggle.mp4
      # Video processing settings for longer videos
      - MAX_UPLOAD_VIDEO_DURATION=600
      - VIDEO_ENCODE_FPS=3
      - VIDEO_ENCODE_MAX_WIDTH=960
      - VIDEO_ENCODE_MAX_HEIGHT=540
      - VIDEO_ENCODE_CODEC=libx264
      - VIDEO_ENCODE_CRF=23
      - FFMPEG_NUM_THREADS=1
    runtime: nvidia
    deploy:
      resources:
        limits:
          memory: 20G
        reservations:
          memory: 16G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
